namespace DGM {

/**

\page DGM_Guide DGM Users Guide

This is the DGM Users Guide which provides detailed instructions on how to
build, setup, run and analyze the results from DGM.  The following quick
links will take you directly to the section of your interest.

\htmlonly
<b>Table of Contents</b>
<ul>
<li> <a href="DGM_Guide.html#DGM_Building">Building DGM</a>
<li> <a href="DGM_Guide.html#DGM_Formulation">DG Formulation</a>
<li> <a href="DGM_Guide.html#DGM_Generating">Generating Meshes</a>
<li> <a href="DGM_Guide.html#DGM_Running">Running DGM</a>
<li> <a href="DGM_Guide.html#DGM_Analyzing">Analyzing DGM Output</a>
</ul>
\endhtmlonly

\section DGM_Building Building and Installing DGM

<a href="../../Install.html">DGM Install Instructions </a>

The DGM build system and many of the run scripts associated with DGM require
that you set the <tt>DGM_DIST</tt> environmental directory to point to the
distribution directory of your DGM source tree.  On my system I use
\verbatim
> setenv DGM_DIST $HOME/dgm
\endverbatim
where we have assumed that DGM was installed in your home directory and
that you are using [t]csh.

The following build instructions give the basics for both serial and
MPI-parallel enabled versions of DGM.  More detailed installation instruction
can be found at \c $DGM_DIST/Install.txt and the reader is encouraged to
consult that document.

\subsection DGM_Serial Serial DGM Build

The simplest procedure for building DGM is as follows.  First, make sure
that you have the required third party libraries available in
<tt>$HOME/local</tt>.  Then, do the following

\verbatim
> cd $DGM_DIST
> mkdir GCC
> cd GCC
> ln -s ../src/Makefile .
> make -j2 dgm
\endverbatim

where the <tt>-j2</tt> tells make to do a parallel build on 2 processors.
You should set this to be close to the number of cores you have on your
system.  This should (at least under Linux and Darwin) leads to a GCC (Gnu
Compiler Collection) build of DGM.  You can make other targets including
many of the drivers and utilities listed at \ref DGM_Executables.  An easy way
to see what make targets are supported is to simply type <tt>make</tt>
which will return an output similar to

\verbatim
 DGM Makefiles:

 Run make with one of the following options:
 a) dgm.....dgm optimized solver
 b) pdgm....dgm parallel optimized solver
 c) mdgm....dgm maximally optimized solver
 d) pmdgm...dgm parallel maximally optimized solver
 e) ddgm....dgm debug solver
 f) mesh....simple mesh generator
 g) n2e.....pre processor
 h) post....post processor
 i) stats...statistics post processor
 j) clean...remove all objects
 k) docs....make Doxygen documentation
 l) opt.....DGM with optimal control
 m) popt....parallel DGM with optimal control
 m) dopt....debug DGM with optimal control
 n) tdd.....time-domain decomposition
 o) cpost...post processor for control output
 p) diff....norm of the difference of two rst files
 q) all.....make all dgm serial codes
 r) pall....make all dgm parallel codes

 ARCH = Darwin-i386, OSVER = 8.11.1, BISON = 1.28
\endverbatim

To quickly build all major DGM targets, simply use 
\verbatim 
make -j8 all
\endverbatim

\subsection DGM_MPI Parallel DGM Build

DGM also supports distributed-memory parallel execution using MPI
communication.  To build an MPI-enabled version of DGM do the following

\verbatim
> cd $DGM_DIST
> mkdir GCCp
> cd GCCp
> ln -s ../src/Makefile .
> ln -s $HOME/local/openmpi mpi
> make -j2 pall
\endverbatim

where we have assumed that you are using a version of OpenMPI that is
available in your <tt>$HOME/local</tt> directory.  Of course, you can use
any functional version of MPI that uses a consistent set of compilers that
you used for the third-party libraries in <tt>$HOME/local</tt>.  Note that
we have used the \c pall target to automatically build all MPI-enabled
targets.

\subsection DGM_Shared Shared Libraries

A common issue when building and running DGM is that some third-party
libraries may default to using shared (or dynamic) libraries which are
resolved at runtime.  For example, under Linux you might need to set
\verbatim
> setenv LD_LIBRARY_PATH $HOME/local/lib:$HOME/local/gsl/lib
\endverbatim
in you <tt>.cshrc</tt> file.  In Darwin (Mac OS-X) you would set
\verbatim
> setenv DYLD_LIBRARY_PATH $HOME/local/lib:$HOME/local/gsl/lib
\endverbatim 

\section DGM_Formulation DG Formulation

This section provides a brief background on discontinuous Galerkin methods.

\image html DGM-formulation.png
<br>
\image html DGM-flux.png

\section DGM_Generating Generating Meshes

Two of the required files are the \ref DGM_MeshFile and the \ref DGM_ConFile,
and they can be generated by the rectangular mesh generator,
\c dgm_mesh.cpp, or by \ref DGM_Converting.

\subsection DGM_Rectangular Rectangular Mesh Generation

To generate a rectangular mesh, the utility \c dgm_mesh.exe can be used,
and help can be obtained by 
\verbatim
> dgm_mesh.exe -help
Simple DGM mesh generator
==================================================
Usage:         dgm_mesh.exe [Options]           
==================================================
Options:       	Description          
==================================================
-nsd <int>     	Number of dimensions 
-nx <int>      	Elements in x        
-ny <int>      	Elements in y        
-nz <int>      	Elements in z        
-Lx <double>   	Length in x          
-Ly <double>   	Length in y          
-Lz <double>   	Length in z          
-x0 <double>   	x offset             
-y0 <double>   	y offset             
-z0 <double>   	z offset             
-Cx <double>   	Stretch in x         
-Cy <double>   	Stretch in y         
-Cz <double>   	Stretch in z         
-Dx <int>      	Stretch dir x [-1:2] 
-Dy <int>      	Stretch dir y [-1:2] 
-Dz <int>      	Stretch dir z [-1:2] 
-theta <double>	Rotation about y-axis
-phi <double>  	Rotation about z-axis
-r <string>    	Root filename        
\endverbatim 

The following will generate a 2D quadrilateral mesh with 850x175 elements
over the domain \f$(x_\text{min},x_\text{max})=(0,17000)\f$ and
\f$(y_\text{min}, y_\text{max})=(0,3500)\f$.

\verbatim 
> dgm_mesh.exe -nsd 2 -nx 850 -ny 175 -x0 0 -y0 0 -Lx 17000 -Ly 3500 -r root
\endverbatim 

Three output files are produced from \c dgm_mesh.exe: \e root.con (the \ref
DGM_ConFile); \e root.dat (a Tecplot ASCII mesh file); and \e root.msh (the \ref
DGM_MeshFile) where \c root is the root filename specified using the <tt> -r
root</tt> parameter.  If no root name is supplied, \c dgm_mesh.exe will use
the name \c new.

Note that DGM uses the native coordinate system shown here

\image html dgm-coords.png

2d problem in DGM are \e always in \f$x, y\f$ while 1d problems are always
in \f$x\f$.  Users must account for this when using <tt>dgm.mesh.exe</tt>.

\subsection DGM_Converting Converting Exodus Meshes

Often one may wish to use an unstructured mesh produced by a mesh
generation package (e.g., Cubit).  One format is the Exodus database,
(i.e., \c root.gen or \c root.exo), which contain information on
the node locations, nodal connectivity, element types, sidesets,
nodesets, attributes, ...  This information can be converted to 
-# \ref DGM_ConFile (\c root.con, ASCII, and/or \c root.cn, binary)
-# \ref DGM_MeshFile (\c root.msh, ASCII, and/or \c root.grd, binary)
-# \ref DGM_BCFile (\c root.bc)
-# \ref DGM_OrderFile (\c root.ord)
-# \ref DGM_CurveFile (\c root.crv)

using \c exo2ien, \c dgm_n2e.exe and dgm_test_support.py scripts.
There are several steps to create these files.  

\subsubsection DGM_exo2ien Using exo2ien

Starting with an Exodus mesh (e.g., \c root.gen or \c root.exo),
one can convert it to ASCII versions of the mesh information, using
\c exo2ien.

\verbatim 
> exo2ien root.gen 
\endverbatim

\c exo2ien creates several files
-# an attribute file, \c att.asc
-# an element connectivity file, \c ien.asc
-# a sideset file, \c side.asc
-# a nodal coordinate file, \c xyz.asc.

Attribute File: \c att.asc

The \c att.asc file contains the attributes specified within Cubit.
An attribute is simply an integer or real defining some quantity
on a block of elements.  Generally it is assumed that all element
blocks have the same number of attributes, and the order of the
attributes is important for utilities in \c dgm_test_support.py
to work correctly.

The current convention is the first attribute is used for specifying
the information about the elements in the element block: curve flag,
polynomial order, and the quadrature order.  These values are encoded
into a single integer using the following formula
\verbatim
  attribute 1 = 10000*c + 100*p + q
\endverbatim
where \c c is the curve flag (0 -> an affine element and 1 -> a
non-affine element), \c p is the polynomial order, and \c q is the
quadrature order.  Using the \c dgm_test_support.py (\c mkcrv_cubit
and \c mkord_cubit), these values can be used to create the curve file
(\c root.crv) to handle skewed elements, and the order file (\c
root.ord) to use variable polynomial and quadrature order.  If \c
p or \c q are set to zero the default value specified in \c root.inp
will be used.

One convention currently used is the attributes are ordered as follows:
<center>
<table border="1" cellpadding="4" cellspacing="0">
<tr>
  <th>Attribute</th>
  <th>%Value</th>
</tr>
<tr>
  <td>1</td>
  <td>Encoded element information (see above)</td>
</tr>
<tr>
  <td>2</td>
  <td>%Material density</td>
</tr>
<tr>
  <td>3</td>
  <td>Primary wave speed</td>
</tr>
<tr>
  <td>4</td>
  <td>Secondary wave speed</td>
</tr>
</table>
</center>

%Element Connectivity File: \c ien.asc

The \c ien.asc file is the traditional finite-element connectivity
listing, where for each element the nodal IDs are listed (a.k.a.
nodal connectivity).  \c ien.asc is used by dgm_n2e.exe to create
the edge connectivity files (\ref DGM_ConFile; \c root.con and/or
root.cn) needed by DGM.

Sideset File: \c side.asc

The \c side.asc file contains information about the sidesets specified
within Cubit, and is used to set boundary conditions on the
mesh boundaries using \c dgm_n2e.exe and optionally \c mkbc_cubit
(\ref DGM_BCFile).

Nodal Coordinate File: \c xyz.asc

The \c xyz.asc file has the \f$(x,y,z)\f$ coordinate locations for the
nodes in the Exodus mesh.  \c xyz.asc is used by \c dgm_n2e.exe to
create the mesh file (\ref DGM_MeshFile; \c root.msh and/or \c
root.grd) needed by DGM.

\subsubsection DGM_dgm_n2e Using dgm_n2e.exe

\c dgm_n2e.cpp uses \c ien.asc, \c side.asc and \c xyz.asc generated
by \c exo2ien to produce the \ref DGM_MeshFile, \ref DGM_ConFile and
\ref DGM_BCFile.  Again <tt>dgm_n2e.exe -help</tt> will provide
basic man page information.  Executing the following command

\verbatim 
> dgm_n2e.exe -r root TFE
\endverbatim 

produces four files:
-# a dual-graph for use with a graph partitioner such as
<a href="http://www.cs.sandia.gov/Zoltan/">Zoltan</a> or <a
href="http://glaros.dtc.umn.edu/gkhome/views/metis">Metis/ParMetis</a>, \e
ien.asc.dgraph
-# the \ref DGM_MeshFile, \c root.msh (ASCII) and/or root.grd (binary)
-# the \ref DGM_ConFile, \c root.con (ASCII) and/or root.cn (binary)
-# the \ref DGM_BCFile, \c root.bc

Note that the last
argument to <tt>dgm_n2e.exe</tt> indicates the input file format where \c
TFE is the traditional finite-element format generated by \c exo2ien. Other
formats are available including \c UCD for GridGen mesh format and \c NEU
for Gambit mesh format.

The \ref DGM_MeshFile contains the nodal locations for each element, and
can be read in two formats: \c root.msh (ASCII) and root.grd (binary).

The \ref DGM_ConFile describes the edge connectivity and similarly has
two formats: \c root.con (ASCII) and root.cn (binary).

\subsubsection DGM_mkbc_cubit Using mkbc_cubit, mkord_cubit, and mkcrv_cubit

The \ref DGM_BCFile generated by dgm_n2e.exe introduces placeholder
variables (i.e., \c bc1, \c bc2, ...) for each sideset.  One needs to
replace these with the appropriate boundary conditions for the given
physics (e.g., absorbing boundary condition, \c Z; Dirichlet boundary
condition, \c D; flux boundary condition, \c F; prescribed boundary
condition, \c S; wall boundary condition, \c W; or user defined
\ref DGM_BCTFile).  Using scripts from \c dgm_test_support.py (\c
mkbc_cubit and \c mkbc_cubit_dict), the above replacement of \c
bc1, \c bc2, ...  with the appropriate boundary conditions can be
automated.  \b Note: These boundary condition codes are examples
only.  The actual values depend on the physical domain being used.

To complete the conversion of Exodus meshes, the optional \ref DGM_OrderFile
and \ref DGM_CurveFile can be created from the first attribute in att.asc.
Using \c mkord_cubit in \c dgm_test_support.py, the \ref DGM_OrderFile,
root.ord, can be made where the polynomial and quadrature order for
every element within each element block will be set according to the
value of its first attribute (see above for details).

Lastly, with most unstructured meshes, quadrilateral elements are generally
be skewed, that is they will not have an affine mapping.  For efficiency,
DGM assumes that every Quad element is affine unless otherwise indicated.
For a general, unstructured quadrilateral mesh, each element will need to
be defined as a general straight-sided element using the \e root.crv
file. If the \ref DGM_CurveFile is not present, the solution will not be
incorrect and will likely lead to unstable simulations.
Using \c mkcrv_cubit in \c dgm_test_support.py, the \ref DGM_CurveFile,
the first attribute can be used to create the curve file, root.crv.
Please refer to \ref DGM_CurveFile for details on the root.crv format.

\section DGM_Running Running DGM

- \ref DGM_InputSpec
- \ref DGM_Examples

\section DGM_Analyzing Analyzing DGM Output

- \ref DGM_OutputSpec

A bibliography for the Reference Manual is provided in:

- \ref DGM_Bibliography

*/

}  // namespace DGM
